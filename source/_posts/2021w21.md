---
title: 2021w21-机器翻译的自动评估
date: 2021-06-02 19:45:02
categories: [学习, 周报]
---

***

> （把每双周周报在BLOG上整理一下，以防止自己做的PPT最后都想不起来是在说什么。）

&ensp;&ensp;&ensp;&ensp;这次周报的题目非常的别扭，可能是我翻译的不太好。英文的话应该是 Automatic Evaluation of Machine Translation ，也就是对机器翻译的结果给出一个自动的评价或者评分，用来对比哪一个机器翻译模型的性能更好。当然，自动也是题目中非常重要的一部分。基于人工的评价自然无法应付现在大规模的评估需求。

<!-- more -->

## 机器翻译及其评估

&ensp;&ensp;&ensp;&ensp;机器翻译是指实现一种语言到另一种语言的自动翻译。[^1] 该系统的输入是语言 A 的一个文本段落。输出是语言 B 的段落。这两个段落都是不定长的文本序列。对于同一句话可能存在多种合理的翻译，也可能存在明显不合理的翻译。例如下图中的最后一个翻译，把 docter 错翻译成博士，显然是不符合原义的。

> ~~（阿米娅：博士，您还有许多事情需要处理。现在还不能休息哦。）~~

![翻译例子](./traneg.png)

[^1]: 宗成庆. 统计自然语言处理[M]. 清华大学出版社, 2013.

&ensp;&ensp;&ensp;&ensp;那么在这么多翻译中，如何评价它们，得出一个更好的翻译呢？这就需要对翻译进行评估，或者称评价。对于如何做好翻译，有大家耳熟能详的严复提出的提出译事三大难：**信**、**达**、**雅**。在 Hovy 等人的论文[^2]中也提出了类似的观点：好的翻译要追求**充分性**（adequacy）、**准确性**（fidelity）和**流畅性**（fluency）。例如在上面的句子中，除了我的翻译无法做到正确之外，有道的翻译则更加流畅，可以认为在这句话上的翻译更好。

[^2]: Hovy E H . Toward Finely Differentiated Evaluation Metrics for Machine Translation[J]. proceedings of the eagles workshop on standards & evaluation.pisa italy.international standards for language engineering, 1999.

&ensp;&ensp;&ensp;&ensp;上述需要人类参与、使用人类对语言的理解的评估可以成为**人工评估**，相对的如果可以计算地得出评估结果，这种可以称为**自动评估**。显然，人工评估不仅费时费力，而且为了弥补人类的不客观性，需要采纳大量人类的结果，显然无法为现今大规模的翻译模型测试提供帮助。由此对自动评估的期望越来越高。对于一个自动评估方案来讲，其通常需要引入由人类提供的**正确答案**（Ground Truth / Reference）。对模型输出的**候选结果**（Candidate）与正确答案进行可重复性的计算，为每个候选结果提供一个表示其翻译质量的分数。自动评估不仅成本低、速度快，而且可以重复，为翻译模型间相互比较提供了可能。

## 传统自动评估方法

### BLEU（The Bilingual Evaluation Understudy）

&ensp;&ensp;&ensp;&ensp;BLEU[^3] 是比较经典的自动评估方法。这个词和蓝色（BLUE）比较像，但看在原论文特意把这四个字母写成蓝色，我觉得读音应该一致。此外经过搜索，BLEU在法语里就是蓝色的意思。

![bleu的翻译](./bleu_tran.png)

[^3]: BLEU

&ensp;&ensp;&ensp;&ensp;BLEU主要分为两部分：n元准确度修改版（Modified $n$-gram precision）、简短惩罚系数（Brevity Penalty）。下面以一个候选句c和多个参考句R为输入。

#### 修改的n元准确度

$$
p_n = \frac{\sum_{n\text{-gram}_\text{uniq} \in c} \text{Count}_\text{clip}(n\text{-gram}_\text{uniq}, R)}{\sum_{n\text{-gram}_\text{uniq}' \in c} \text{Count}(n\text{-gram}_\text{uniq}', c)}
$$

&ensp;&ensp;&ensp;&ensp;该公式计算的是准确率（相对于召回率），统计的是**候选句$c$**中出现在**句子$R$**中的$n$-gram数量占所有$n$-gram数量的比例。但与普通的准确率不同的是，BLEU对分子部分进行裁切，使同一个n-gram的匹配数量得到限制。先看公式。

$$
\text{Count}_\text{clip}(n\text{-gram}, R) = \min(\text{Count}(n\text{-gram}, c), \max_{r \in R}(\text{Count}(n\text{-gram}, r)))
$$

&ensp;&ensp;&ensp;&ensp;其中：

$$
\text{Count}(n\text{-gram}, w)= \sum_{n\text{-gram}'\in w} I(n\text{-gram}, n\text{-gram}') 
$$

$$
I(a,b) = \begin{cases}
1 \quad \text{if} \ a = b \\
0 \quad \text{else}
\end{cases}
$$

&ensp;&ensp;&ensp;&ensp;该公式说明的是每一个$n$-gram，都不能超过参考句中匹配数量最大的一项。这样说很抽象，以下面的例子作为参考。

![n元准确度的例子](./bleueg1.png)

&ensp;&ensp;&ensp;&ensp;我们计算这个例子的1元准确度。可以发现 the 在参考句 1 和参考句 2 中分别出现了 2 次和 1 次。那么 $1$-gram 在其中的最大匹配数为 2. 因此最终的1元准确率为 $\frac{2}{7}$.

$$
\text{Count}_\text{clip}(\text{[the]}, R) = \min(7, \max(2, 1)) = 2
$$

$$
p_1 = \frac{2}{7}
$$

#### 简短惩罚系数

