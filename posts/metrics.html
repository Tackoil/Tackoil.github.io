<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.61">
    <link rel="icon" href="/assets/avatar.png"><link rel="apple-touch-icon" href="/assets/avatar.png"><title>距离整理笔记 | Tackoil's WebSite</title><meta name="description" content="本篇是在日常看论文的时候所整理的关于**距离**或者**度量**的内容。主要会记录一些度量的方法，和这种度量方法所适用的范围。">
    <link rel="preload" href="/assets/style-a6f4830c.css" as="style"><link rel="stylesheet" href="/assets/style-a6f4830c.css">
    <link rel="modulepreload" href="/assets/app-c9fab85c.js"><link rel="modulepreload" href="/assets/framework-1508a596.js"><link rel="modulepreload" href="/assets/metrics.html-77c2ecc8.js"><link rel="modulepreload" href="/assets/metrics.html-af21ffb3.js"><link rel="prefetch" href="/assets/index.html-eb8c85a2.js" as="script"><link rel="prefetch" href="/assets/about.html-91f1e27d.js" as="script"><link rel="prefetch" href="/assets/links.html-2eb2e38a.js" as="script"><link rel="prefetch" href="/assets/2021-winter-solstice.html-61365fa2.js" as="script"><link rel="prefetch" href="/assets/2021a10.html-5477114f.js" as="script"><link rel="prefetch" href="/assets/2021s12.html-6be15c11.js" as="script"><link rel="prefetch" href="/assets/2022-winter-solstice.html-f058b686.js" as="script"><link rel="prefetch" href="/assets/2023-summer-solstice.html-7f466ccb.js" as="script"><link rel="prefetch" href="/assets/2023-winter-solstice.html-1f029375.js" as="script"><link rel="prefetch" href="/assets/axios-promise.html-17f0856e.js" as="script"><link rel="prefetch" href="/assets/css-hacky.html-ee503659.js" as="script"><link rel="prefetch" href="/assets/js-destructuring-assignment.html-5e0ba172.js" as="script"><link rel="prefetch" href="/assets/linguistics.html-47836ab6.js" as="script"><link rel="prefetch" href="/assets/nn0.html-b3d03f0c.js" as="script"><link rel="prefetch" href="/assets/oped-view.html-994e76b2.js" as="script"><link rel="prefetch" href="/assets/oped-view2.html-a1913a70.js" as="script"><link rel="prefetch" href="/assets/pcrtest.html-7e5c31c2.js" as="script"><link rel="prefetch" href="/assets/repeater.html-fd93589d.js" as="script"><link rel="prefetch" href="/assets/404.html-e0575d4e.js" as="script"><link rel="prefetch" href="/assets/index.html-3b00b1e7.js" as="script"><link rel="prefetch" href="/assets/about.html-62eef9fe.js" as="script"><link rel="prefetch" href="/assets/links.html-d4412946.js" as="script"><link rel="prefetch" href="/assets/2021-winter-solstice.html-6804d0dc.js" as="script"><link rel="prefetch" href="/assets/2021a10.html-2dc2b5ab.js" as="script"><link rel="prefetch" href="/assets/2021s12.html-8a7c2b08.js" as="script"><link rel="prefetch" href="/assets/2022-winter-solstice.html-eb6388a4.js" as="script"><link rel="prefetch" href="/assets/2023-summer-solstice.html-cae31e79.js" as="script"><link rel="prefetch" href="/assets/2023-winter-solstice.html-d8444542.js" as="script"><link rel="prefetch" href="/assets/axios-promise.html-9b9e9f65.js" as="script"><link rel="prefetch" href="/assets/css-hacky.html-620b5808.js" as="script"><link rel="prefetch" href="/assets/js-destructuring-assignment.html-e46e743f.js" as="script"><link rel="prefetch" href="/assets/linguistics.html-f90b03cc.js" as="script"><link rel="prefetch" href="/assets/nn0.html-acc71412.js" as="script"><link rel="prefetch" href="/assets/oped-view.html-05745966.js" as="script"><link rel="prefetch" href="/assets/oped-view2.html-5dfee8e5.js" as="script"><link rel="prefetch" href="/assets/pcrtest.html-c0ed3304.js" as="script"><link rel="prefetch" href="/assets/repeater.html-94304ced.js" as="script"><link rel="prefetch" href="/assets/404.html-9fc9f571.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><header class="nav-bar"><div class="nav-bar-container"><span class="nav-bar__title">Tackoil&#39;s WebSite</span><div class="button-group"><!--[--><button class="button-group__button"><i class="iconfont icon-home"></i><div class="shrink-content" style="width:40px;"><div><!--[--><span>首页</span><!--]--></div></div></button><button class="button-group__button"><i class="iconfont icon-user"></i><div class="shrink-content" style="width:40px;"><div><!--[--><span>关于</span><!--]--></div></div></button><button class="button-group__button"><i class="iconfont icon-link"></i><div class="shrink-content" style="width:40px;"><div><!--[--><span>友链</span><!--]--></div></div></button><!--]--></div></div></header><div class="head-pic" style="transform:translateY(NaNpx);"><div class="head-pic__title" style="transform:translateY(-0vh);">距离整理笔记</div><div class="head-pic__mask"></div><div class="head-pic__pic" style="filter:blur(0px);background-image:url(https://wonder-egg-priority.com/assets/img/top/main/visual.jpg);"></div></div><div class="page-card__container" style="transform:translateY(-0vh);margin-bottom:-0vh;"><div class="page-card"><!--[--><!--[--><!--[--><div class="post-title">距离整理笔记</div><div class="markdown-body markdown-body--indent"><p>本篇是在日常看论文的时候所整理的关于<strong>距离</strong>或者<strong>度量</strong>的内容。主要会记录一些度量的方法，和这种度量方法所适用的范围。</p><!-- more --><h1 id="version" tabindex="-1"><a class="header-anchor" href="#version" aria-hidden="true">#</a> Version</h1><ul><li>ver0.1 2019/11/6 创建文档</li></ul><h1 id="编辑距离" tabindex="-1"><a class="header-anchor" href="#编辑距离" aria-hidden="true">#</a> 编辑距离</h1><h2 id="汉明距离" tabindex="-1"><a class="header-anchor" href="#汉明距离" aria-hidden="true">#</a> 汉明距离</h2><p>设$x$，$y$为两个长度为$n$的二进制向量，则汉明距离为</p><p>$$ \begin{aligned} d(x, y) = \sum_{i=1}^n I(x_i, y_i) \ I(a, b) = \begin{cases} 1, &amp; a = b \ 0, &amp; \text{else} \ \end{cases} \end{aligned} $$</p><p>汉明距离满足<strong>距离公理</strong>：非负性、对称性、三角不等式。</p><h2 id="levenshtein距离" tabindex="-1"><a class="header-anchor" href="#levenshtein距离" aria-hidden="true">#</a> Levenshtein距离</h2><p>设$x$，$y$是两个字符串。那么Levenshtein距离定义为：将$s_1$转换成$s_2$的最小<strong>编辑操作</strong>数。通常，这样的编辑操作包括：</p><ol><li>将一个字符插入字符串</li><li>从字符串中删除一个字符</li><li>将字符串中的一个字符替换成另外一个字符</li></ol><p>关于该编辑距离是否可以满足距离的三定义（非负性，对称性，三角不等式）只查到已被证明，但没有查询到相关的证明过程。在维基百科的 <a href="https://en.wikipedia.org/wiki/Edit_distance" target="_blank" rel="noopener noreferrer">编辑距离</a> 词条中，简单的说明了该编辑距离满足距离定义。简略翻译如下：</p><blockquote><p>具有非负成本(non-negative cost)的编辑距离满足距离公理(the axioms of a metric)。当满足以下条件时，该编辑距离生成一个距离空间(metric space)：</p><ul><li>每一个编辑操作都具有正成本。</li><li>对于每一个编辑操作，都有相同成本的逆操作(inverse operation)。</li></ul><p>具有以上这些属性，将满足如下的距离公理：</p><ul><li>$d(a,b) = 0$当且仅当$a = b$，因为每一个字符串都可以通过0个操作转换成自身。</li><li>$d(a,b) &gt; 0$当$a \neq b$，因为这将至少需要一个操作。</li><li>$d(a,b) = d(b,a)$，每一个操作的成本与其逆操作的成本是相同的。</li><li>$d(a,c) \leq d(a,b) + d(b,c)$，三角不等式。</li></ul><p>Levenshtein distance 和 LCS distance 具有单元成本并满足以上条件，因此满足距离公理。一些编辑距离的变体即使不是真正的(proper)距离，也被在一些文献中使用。</p></blockquote><p>该距离由递推式定义：</p><p>$$ d(x[0:i], y[0:j]) = \begin{cases} \max (i, j) &amp; \text{if} \min(i, j) = 0 \min \begin{cases} d(x[0:i-1], y[0:j]) +1 \ d(x[0:i],y[0:j-1]) +1 \ d(x[0:i-1], y[0:j-1]) + 1 _{(x_i \neq y_j)}<br> \end{cases} &amp; \text{otherwise} \end{cases} $$</p><h2 id="max-match-m-2-evaluation" tabindex="-1"><a class="header-anchor" href="#max-match-m-2-evaluation" aria-hidden="true">#</a> Max-Match($M^2$) Evaluation</h2><p><a href="https://www.aclweb.org/anthology/N12-1067/" target="_blank" rel="noopener noreferrer">Paper: Better Evaluation for Grammatical Error Correction</a></p><p>我们这里提到的评估，有以下的限制与使用环境。</p><ul><li>我们对两个句子$C$，$S$进行评估，并使用“黄金标准”$G$决定性评价句子。</li><li>评估的最小粒度为单词（词条）。</li><li>我们希望这个评估可以对包含$G$的$C$给予<strong>较高</strong>的分数，对接近$S$的$C$给予<strong>较低</strong>的分数。</li></ul><p>文章中使用了一种称之为**编辑晶格（Edit lattice）**的方法辅助计算该调整过的距离。首先，我们计算$C$和$S$在单词（词条）粒度上的编辑距离。在计算编辑距离时会使用表格进行动态规划。之后将这个表格转化成一个有向无环图。便于理解，我们按照下面的步骤进行生成。</p><ol><li>首先我们将表格中的最优编辑（编辑距离最小的编辑方式）画成如图所示的有向无环图。</li><li>我们定义了合并过程中的不变单词的最大数量$u$，这里我们让$u=2$，这也是文章中的默认配置。</li><li>我们开始对编辑操作进行合并：对任意两个结点进行连线，并满足第二条的<strong>不变单词的最大数量</strong>的限制，从而得到完整的有向无环图。</li><li>我们对所有的单位操作赋予权值$1$，对于合并的操作赋予被合并的权值之和。此外，我们将黄金标准中的编辑操作赋予权值$-(u+1) \times |E|$，其中$|E|$是这张图中的边的总数。也就是含有黄金标准的路径将<strong>一定</strong>会获得一个负数的权值。这样，我们就得到了一个<strong>编辑晶格</strong>。</li></ol><p>之后计算$M^2$距离时，仅需要先计算$C$，$S$的最小权值路径所对应的编辑操作$e$。对于所有的测试句子的编辑操作组成一个集合$\lbrace e_1, \cdots, e_n \rbrace$，与其对应的黄金标准集合为$\lbrace g_1, \cdots , g_n \rbrace$。之后计算两个集合的准确率、召回率和$F_1$分数即可。 $$ \begin{aligned} P &amp;= \frac{\sum_{i=1}^n | e_i \cap g_i |}{\sum_{i=1}^n | e_i | } \ R &amp;= \frac{\sum_{i=1}^n | e_i \cap g_i |}{\sum_{i=1}^n |g_i|} \ F_1 &amp;= 2 \times \frac{P \times R}{P + R} \end{aligned} $$ 这里的$|e_i \cap g_i |$表示的是$e_i$操作是否与$g_i$操作match。 $$ \mathrm{match}(e,g) \Leftrightarrow (e.a = g.a) \land (e.b = g,b) \land (e.C \in g.C) $$</p><h1 id="二元素度量" tabindex="-1"><a class="header-anchor" href="#二元素度量" aria-hidden="true">#</a> 二元素度量</h1><h2 id="bleu" tabindex="-1"><a class="header-anchor" href="#bleu" aria-hidden="true">#</a> BLEU</h2><p><a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener noreferrer">Paper: BLEU: a Method for Automatic Evaluation of Machine Translation</a></p><p>BLEU是为<strong>机器翻译</strong>准备的评估方法。以单词（词条）为单位，计算候选句$C$与参考句$R$的距离。原论文可以计算多个候选句与多个参考句之间的距离，这里我们将其简化为一个候选句与多个参考句的距离（当然也可以一对一）。</p><p>公式直接列举在下面了，感觉下面的定义足够的详细。 $$ \mathrm{BLEU}(c;R) = \mathrm{BP}(c;R) \cdot \exp \left( \sum_{n=1}^{N} w_N \log p_n\right) $$</p><p>$$ \mathrm{BP}(c;R) = \begin{cases} 1 \quad &amp;\text{if}\ \mathrm{len}(c) &gt; \mathrm{len}(r^\star)\ \exp(1-\frac{\mathrm{len}(r^\star)}{\mathrm{len}(c)}) &amp;\text{if}\ \mathrm{len}(c) \leq \mathrm{len}(r^\star) \end{cases} $$</p><p>$$ r^\star = \arg \min_{r \in R} \left| \mathrm{len}(r) - \mathrm{len}(c)\right| $$</p><p>$$ w_N = \frac{1}{N} $$</p><p>$$ p_n = \frac{\sum_{n\text{-gram} \in c} \mathrm{Count_{clip}}(n\text{-gram})}{\sum_{n\text{-gram}&#39; \in c} \mathrm{Count}(n\text{-gram}&#39;)} $$</p><p>$$ \mathrm{Count_{clip}}(n\text{-gram}) = \min(\mathrm{Count}(n\text{-gram},c),\max_{r \in R}(\mathrm{Count(n\text{-gram},r)})) $$</p><p>$$ \mathrm{Count}(n\text{-gram}, w) = \sum_{n\text{-gram}&#39; \in w} I(n\text{-gram}, n\text{-gram}&#39;) $$</p><p>$$ I(a,b) = \begin{cases} 1 &amp; \text{if}\ a = b \ 0 &amp; \text{else} \end{cases} $$ 简单概括下，主要分为以下步骤。</p><ul><li>计算截断数量$\mathrm{Count}_\mathrm{clip}$</li><li>计算准确度$p_n$</li><li>计算长度惩罚系数$\mathrm{BP}(c;R)$</li><li>最终得出$\mathrm{BLEU}(c;R)$</li></ul><h1 id="三元素度量" tabindex="-1"><a class="header-anchor" href="#三元素度量" aria-hidden="true">#</a> 三元素度量</h1><h2 id="i-measure-evaluation" tabindex="-1"><a class="header-anchor" href="#i-measure-evaluation" aria-hidden="true">#</a> I-measure Evaluation</h2><p><a href="https://www.aclweb.org/anthology/N15-1060/" target="_blank" rel="noopener noreferrer">Paper: Towards a standard evaluation method for grammatical error detection and correction</a></p><p>我们这里提到的评估，有以下的限制与使用环境。</p><ul><li>我们对三个句子$C$，$S$，$R$进行评估。</li><li>评估的最小粒度为单词（词条）。</li><li>我们希望这个评估可以对接近$R$的$C$给予<strong>较高</strong>的分数，对接近$S$的$C$给予<strong>较低</strong>的分数。</li></ul><p>文章的核心在于使用了<strong>SP对齐（the Sum of Pairs alignment）的方式</strong>，将三个句子同时对齐。同样是基于Levenshtein距离的方法，我们对插入删除操作（gap）和替换操作（mismatch）分别赋予不同的代价（cost），分别为$c_\text{gap}$，$c_\text{mis}$，得到一种总代价最小的对齐方案。</p><p><em>该算法该天再补。</em></p><p>之后的部分是计算PRF1。首先，我们使用改进版的<em>WAS</em>方法定义TP、TN、FP、FN。</p><table><thead><tr><th style="text-align:center;"></th><th style="text-align:center;">Written（Source）</th><th style="text-align:center;">Annotated（Reference）</th><th style="text-align:center;">System（Candidate）</th></tr></thead><tbody><tr><td style="text-align:center;">TN</td><td style="text-align:center;">X</td><td style="text-align:center;">X</td><td style="text-align:center;">X</td></tr><tr><td style="text-align:center;">FP</td><td style="text-align:center;">X</td><td style="text-align:center;">X</td><td style="text-align:center;">Y</td></tr><tr><td style="text-align:center;">FN</td><td style="text-align:center;">X</td><td style="text-align:center;">Y</td><td style="text-align:center;">X</td></tr><tr><td style="text-align:center;">TP</td><td style="text-align:center;">X</td><td style="text-align:center;">Y</td><td style="text-align:center;">Y</td></tr><tr><td style="text-align:center;">FPN</td><td style="text-align:center;">X</td><td style="text-align:center;">Y</td><td style="text-align:center;">Z</td></tr></tbody></table><p>简单解释，我们将W与A是否匹配分成两类：不匹配（即需要更改）【P】、匹配（即不需要更改）【N】。由此我们可以将S的预测分为TP、TN、FP、FN四类。因为在本次计算中，我们还会遇到最后一种情况，此时我们将其定义为FPN类。这样，我们得出加权准确性指标。 $$ \mathrm{WAcc} = \frac{w \cdot \mathrm{TP} + \mathrm{TN}}{w \cdot \mathrm{TP} + \mathrm{TN} + w \cdot (\mathrm{FP} - \frac{\mathrm{FPN}}{2}) + (\mathrm{FN} - \frac{\mathrm{FPN}}{2})} $$ 我们希望给予$\mathrm{TP}$多于$\mathrm{TN}$的奖励（即正确的更改好于不更改）；我们希望基于$\mathrm{FP}$多于$\mathrm{FN}$的惩罚（即错误的更改不如不更改），因此这里$w \geq 1$。通常$w = 2$。</p><p>最后为了对比在不同数据集下的模型情况，我们构建了每个数据集格子的基线标准，即：将Reference直接作为Candidate，计算加权准确性指标$\mathrm{WAcc}<em>{\text{base}}$，然后我们得到I-measure $$ I = \begin{cases} \lfloor \mathrm{WAcc}</em>{\text{sys}} \rfloor &amp; \text{if}\ \mathrm{WAcc}<em>{\text{sys}} = \mathrm{WAcc}</em>{\text{base}} \ \frac{\mathrm{WAcc}<em>{\text{sys}} - \mathrm{WAcc}</em>{\text{base}}}{1 - \mathrm{WAcc}<em>{\text{base}}} &amp; \text{if}\ \mathrm{WAcc}</em>{\text{sys}} &gt; \mathrm{WAcc}<em>{\text{base}} \ \frac{\mathrm{WAcc}</em>\text{sys}}{\mathrm{WAcc}_\text{base}} - 1 &amp; \text{otherwise} \end{cases} $$</p><h2 id="gleu" tabindex="-1"><a class="header-anchor" href="#gleu" aria-hidden="true">#</a> GLEU</h2><p><a href="https://www.aclweb.org/anthology/P15-2097/" target="_blank" rel="noopener noreferrer">Paper: Ground Truth for Grammatical Error Correction Metrics</a></p><p><a href="https://arxiv.org/abs/1605.02592" target="_blank" rel="noopener noreferrer">Paper: GLEU Without Tuning</a></p><p>本文将主要介绍升级版的GLEU，他们称之为$\mathrm{GLEU^+}$。更新版的GLEU+相对于原始版本的GLEU，不仅去掉了一个需要特殊训练的参数$\lambda$，计算公式也更加合理易懂，所以我们将主要介绍这个。</p><p>我们这里提到的评估，有以下的限制与使用环境。</p><ul><li>我们对三个句子$C$，$S$，$R$进行评估。</li><li>评估的最小粒度为单词（词条）。</li><li>我们希望这个评估可以对接近$R$的$C$给予<strong>较高</strong>的分数，对接近$S$的$C$给予<strong>较低</strong>的分数。</li></ul><p>该算法大体与BLEU一致，为了适应语法错误更正这个任务(GEC)，我们要修改截断计数。这里我们大体沿用BLEU部分的式子，只对$p_n$进行修改： $$ \mathrm{GLEU}(c,r,s) = \mathrm{BP}(c; r) \cdot \exp \left( \sum_{n=1}^N w_N \log p^\star_n\right) $$</p><p>$$ p^\star_n = \frac{\sum_{n\text{-gram} \in c \cap r } \mathrm{Count}<em>{c, r} (n\text{-gram}) - \sum</em>{n\text{-gram} \in c \cap s} \max \left[ 0, \mathrm{Count}<em>{c, s}(n\text{-gram}) - \mathrm{Count}</em>{c, r}(n\text{-gram}) \right] }{\sum_{n\text{-gram}&#39; \in c} \mathrm{Count}_c (n\text{-gram}&#39;)} $$</p><p>$$ \mathrm{Count}_{A,B}(n\text{-gram}) = \min \left[ \mathrm{Count}_A (n \text{-gram}), \mathrm{Count}_B (n \text{-gram}) \right] $$</p><p>$$ \mathrm{Count}<em>A (n\text{-gram}) = \sum</em>{n\text{-gram}&#39; \in A} I(n\text{-gram}, n\text{-gram}&#39;) $$</p><h1 id="向量度量" tabindex="-1"><a class="header-anchor" href="#向量度量" aria-hidden="true">#</a> 向量度量</h1><h2 id="p-范数" tabindex="-1"><a class="header-anchor" href="#p-范数" aria-hidden="true">#</a> $p$-范数</h2><p>各个领域都很常用的范数，用来度量向量应该是比较成熟的理论了。 $$ \Vert x \Vert_p = \left( \vert x_1 \vert^p + \vert x_2 \vert^p + \cdots + \vert x_n \vert^p \right)^{1/p} $$</p><h3 id="_1-范数" tabindex="-1"><a class="header-anchor" href="#_1-范数" aria-hidden="true">#</a> $1$-范数</h3><p>$$ \Vert x \Vert_1 = \vert x_1 \vert + \vert x_2 \vert + \cdots + \vert x_n \vert $$</p><p>1-范数有比较好的鲁棒性，根据罚函数的理论，其在大的$x_i$上，罚函数上升较慢。</p><h3 id="_2-范数" tabindex="-1"><a class="header-anchor" href="#_2-范数" aria-hidden="true">#</a> $2$-范数</h3><p>$$ \Vert x \Vert_2 = \left( \vert x_1 \vert^2 + \vert x_2 \vert^2 + \cdots + \vert x_n \vert^2 \right)^{1/2} $$</p><p>这个就是大家都很常用的欧氏距离了。也是最小二乘法所使用的范数。</p><h3 id="infty-范数" tabindex="-1"><a class="header-anchor" href="#infty-范数" aria-hidden="true">#</a> $\infty$-范数</h3><p>$$ \Vert x \Vert_\infty = \max \left( \vert x_1 \vert , \vert x_2 \vert , \cdots , \vert x_n \vert \right) $$</p><p>总之也能有用的上的地方吧。（比如说对数据的上下界有极为严格的定义，之类的。）</p><h1 id="概率分布度量" tabindex="-1"><a class="header-anchor" href="#概率分布度量" aria-hidden="true">#</a> 概率分布度量</h1><p>如果要认为这个也是向量度量的话，也不是不可以。这里就将对概率化的向量的度量单独列出来了。</p><h2 id="相对熵-kullback-leibler散度" tabindex="-1"><a class="header-anchor" href="#相对熵-kullback-leibler散度" aria-hidden="true">#</a> 相对熵（Kullback-Leibler散度）</h2><p>源自信息论理论中的一个度量。用来度量两个概率分布的差异。</p><p><strong>注意：这是一个非对称的度量，换句话说，这个度量不符合标准的距离定义。</strong> $$ \mathrm{KL}(p \Vert q) = \sum p(x) \log \frac{p(x)}{q(x)} $$</p><h2 id="交叉熵" tabindex="-1"><a class="header-anchor" href="#交叉熵" aria-hidden="true">#</a> 交叉熵</h2><p>很不幸的是，交叉熵也不具有对称性。通常我们认为某一个分布是已知的，我们用q去逼近p，在这种情况下，相对熵可以表示为： $$ \begin{aligned} \mathrm{KL}(p \Vert q ) &amp;= \sum p(x) \log p(x) - \sum p(x) \log q(x) \ &amp;= -H(p) + H(p \Vert q) \end{aligned} $$ 我们称$H(p \Vert q)$为交叉熵，定义为： $$ H(p \Vert q) = - \sum p(x) \log q(x) $$ 这里使用了可能和大多数博客不一样的符号。为了区别联合熵$H(p,q)$，因此没有使用逗号。为了区别条件熵$H(p \vert q)$，因此没有使用单竖线。为了看起来保持了相对熵不对称的性质，因此使用了双竖线。</p></div><!--]--><!--]--><!--]--></div></div><footer class="footer" data-v-c22f8b03><div class="footer-content" data-v-c22f8b03> Base VuePress by <a href="https://github.com/Tackoil/vuepress-theme-anemos" data-v-c22f8b03>Anemos</a></div></footer><!--]--><!--]--></div>
    <script type="module" src="/assets/app-c9fab85c.js" defer></script>
  </body>
</html>
